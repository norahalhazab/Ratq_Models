{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858fff7d",
   "metadata": {},
   "source": [
    "# Cell 2 â€” TensorFlow Configuration (GPU, Precision, XLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef1440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Logical devices: [LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "print(\"Logical devices:\", tf.config.list_logical_devices())\n",
    "\n",
    "tf.config.optimizer.set_jit(False)   # keep OFF\n",
    "\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "tf.keras.utils.set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3df2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.10.1\n",
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPUs:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c175e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: <Policy \"float32\">\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy(\"float32\")\n",
    "print(\"Policy:\", mixed_precision.global_policy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e4cf5a",
   "metadata": {},
   "source": [
    "# Cell 3 -Load CSV Flies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e336ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSVs found\n"
     ]
    }
   ],
   "source": [
    "# âœ… Train on augmented images\n",
    "TRAIN_DIR = \"SurgWound_Augmented\"\n",
    "TRAIN_CSV = os.path.join(TRAIN_DIR, \"train_aug_data.csv\")\n",
    "\n",
    "# âœ… Validate/Test on clean images\n",
    "CLEAN_DIR = \"SurgWound_Cleaned\"\n",
    "VAL_CSV   = os.path.join(CLEAN_DIR, \"validation_data.csv\")\n",
    "TEST_CSV  = os.path.join(CLEAN_DIR, \"test_data.csv\")\n",
    "\n",
    "assert os.path.exists(TRAIN_CSV), \"Missing train_aug_data.csv\"\n",
    "assert os.path.exists(VAL_CSV), \"Missing validation_data.csv\"\n",
    "assert os.path.exists(TEST_CSV), \"Missing test_data.csv\"\n",
    "print(\"âœ… CSVs found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fad632",
   "metadata": {},
   "source": [
    "#  Cell 4 â€” Load & Filter Erythema Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f46944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " answer\n",
      "Non-existent    2004\n",
      "Existent         774\n",
      "Name: count, dtype: int64\n",
      "Val:\n",
      " answer\n",
      "Non-existent    44\n",
      "Existent        22\n",
      "Name: count, dtype: int64\n",
      "Test:\n",
      " answer\n",
      "Non-existent    91\n",
      "Existent        40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def load_task(df, task_key=\"erythema\"):\n",
    "    df = df.copy()\n",
    "    df = df[df[\"image_id\"].astype(str).str.contains(task_key, case=False, na=False)]\n",
    "    df = df[df[\"answer\"].astype(str).str.lower() != \"uncertain\"]\n",
    "    df[\"answer\"] = df[\"answer\"].astype(str).str.strip()\n",
    "    df[\"filename\"] = (\n",
    "        df[\"filename\"].astype(str)\n",
    "        .str.replace(\"\\\\\\\\\", \"/\", regex=False)\n",
    "        .str.replace(\"\\\\\", \"/\", regex=False)\n",
    "    )\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "train_df = load_task(pd.read_csv(TRAIN_CSV), \"erythema\")\n",
    "val_df   = load_task(pd.read_csv(VAL_CSV),   \"erythema\")\n",
    "test_df  = load_task(pd.read_csv(TEST_CSV),  \"erythema\")\n",
    "\n",
    "print(\"Train:\\n\", train_df[\"answer\"].value_counts())\n",
    "print(\"Val:\\n\", val_df[\"answer\"].value_counts())\n",
    "print(\"Test:\\n\", test_df[\"answer\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90fc231",
   "metadata": {},
   "source": [
    "# Cell 5 â€” Dataset Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103b7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train file: train/images/0.jpg_erythema.jpg\n",
      "Exists? True\n",
      "âœ… Paths OK\n"
     ]
    }
   ],
   "source": [
    "p = os.path.join(TRAIN_DIR, train_df[\"filename\"].iloc[0])\n",
    "print(\"Example train file:\", train_df[\"filename\"].iloc[0])\n",
    "print(\"Exists?\", os.path.exists(p))\n",
    "assert os.path.exists(p), \"âŒ Train augmented image path mismatch.\"\n",
    "print(\"âœ… Paths OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6a0c8",
   "metadata": {},
   "source": [
    "# Cell 6 â€” Image Size & Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf61fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 8   # if still OOM -> 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffa7d4c",
   "metadata": {},
   "source": [
    "# Cell 7 â€” Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8054d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2778 validated image filenames belonging to 2 classes.\n",
      "Found 66 validated image filenames belonging to 2 classes.\n",
      "Found 131 validated image filenames belonging to 2 classes.\n",
      "âœ… class_indices: {'Existent': 0, 'Non-existent': 1}\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=20.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10,\n",
    "    zoom_range=0.20,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator()  # clean, no augmentation\n",
    "\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=TRAIN_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"answer\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory=CLEAN_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"answer\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = val_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=CLEAN_DIR,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"answer\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"sparse\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"âœ… class_indices:\", train_gen.class_indices)\n",
    "NUM_CLASSES = len(train_gen.class_indices)\n",
    "assert NUM_CLASSES == 2, \"Expected 2 classes for erythema.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbeb157",
   "metadata": {},
   "source": [
    "# Cell 8 â€” Training Utilities (Compile & Fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee260036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 1.7945736434108528, 1: 0.6931137724550899}\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_gen.classes, dtype=int)\n",
    "classes = np.arange(NUM_CLASSES, dtype=int)\n",
    "\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "CLASS_WEIGHTS = {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "print(\"Class weights:\", CLASS_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e06cafa",
   "metadata": {},
   "source": [
    "# Cell 9,10 â€” Evaluation & Threshold Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_bn(model):\n",
    "    for l in model.layers:\n",
    "        if isinstance(l, layers.BatchNormalization):\n",
    "            l.trainable = False\n",
    "\n",
    "def compile_model(model, lr, label_smoothing=0.0):\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    if label_smoothing and label_smoothing > 0:\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(label_smoothing=label_smoothing)\n",
    "    else:\n",
    "        loss_fn = \"sparse_categorical_crossentropy\"\n",
    "\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def fit_model(model, epochs, lr):\n",
    "    compile_model(model, lr=lr)\n",
    "    cbs = [\n",
    "        ReduceLROnPlateau(monitor=\"val_loss\", patience=2, factor=0.5, min_lr=1e-7, verbose=1),\n",
    "        EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True, verbose=1),\n",
    "    ]\n",
    "    return model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        class_weight=CLASS_WEIGHTS,\n",
    "        callbacks=cbs,\n",
    "        verbose=1,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a75bd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(model, loader):\n",
    "    probs = model.predict(loader, verbose=0)\n",
    "    probs = np.array(probs)\n",
    "    if probs.ndim == 1:\n",
    "        probs = np.stack([1 - probs, probs], axis=1)\n",
    "    return probs\n",
    "\n",
    "def eval_on_test(model):\n",
    "    probs = predict_probs(model, test_gen)\n",
    "    y_pred = np.argmax(probs, axis=1)\n",
    "    y_true = np.array(test_gen.classes, dtype=int)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    return acc, f1w, y_true, y_pred, probs\n",
    "\n",
    "def best_threshold_on_val(model):\n",
    "    probs = predict_probs(model, val_gen)\n",
    "    y_val = np.array(val_gen.classes, dtype=int)\n",
    "\n",
    "    # pick positive class index safely\n",
    "    if \"Existent\" in train_gen.class_indices:\n",
    "        ex_idx = train_gen.class_indices[\"Existent\"]\n",
    "    else:\n",
    "        ex_idx = 1  # fallback: assume class 1 is positive\n",
    "\n",
    "    p_ex = probs[:, ex_idx]\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in np.arange(0.05, 0.96, 0.01):\n",
    "        y_pred_t = np.where(p_ex >= t, ex_idx, 1 - ex_idx)\n",
    "        f1w_t = f1_score(y_val, y_pred_t, average=\"weighted\", zero_division=0)\n",
    "        if f1w_t > best_f1:\n",
    "            best_f1, best_t = f1w_t, t\n",
    "    return float(best_t), float(best_f1)\n",
    "\n",
    "def eval_threshold(model, t):\n",
    "    probs = predict_probs(model, test_gen)\n",
    "    y_true = np.array(test_gen.classes, dtype=int)\n",
    "\n",
    "    if \"Existent\" in train_gen.class_indices:\n",
    "        ex_idx = train_gen.class_indices[\"Existent\"]\n",
    "    else:\n",
    "        ex_idx = 1\n",
    "\n",
    "    p_ex = probs[:, ex_idx]\n",
    "    y_pred = np.where(p_ex >= t, ex_idx, 1 - ex_idx)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    return float(acc), float(f1w), y_true, y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57a525",
   "metadata": {},
   "source": [
    "# Cell 11 â€” Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion(y_true, y_pred, title):\n",
    "    labels = {v: k for k, v in train_gen.class_indices.items()}\n",
    "    class_names = [labels[i] for i in range(len(labels))]\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(5.5, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593fdb7",
   "metadata": {},
   "source": [
    "# Cell 12 â€” Model Architectures & Head Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetV2S, ConvNeXtTiny, ResNet101V2\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as effv2_preprocess\n",
    "from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnetv2_preprocess\n",
    "from tensorflow.keras.applications import EfficientNetV2M\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input as effv2_preprocess\n",
    "from tensorflow.keras.applications import DenseNet121, DenseNet169, DenseNet201\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "\n",
    "def build_head(x, num_classes=2):\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.45)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # âœ… important for mixed precision stability\n",
    "    return layers.Dense(num_classes, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "\n",
    "def make_model(backbone_name):\n",
    "    inp = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "\n",
    "    if backbone_name == \"ConvNeXtTiny\":\n",
    "        x = layers.Lambda(convnext_preprocess, name=\"convnext_preprocess\")(inp)\n",
    "        base = ConvNeXtTiny(include_top=False, weights=\"imagenet\", include_preprocessing=False)\n",
    "        feats = base(x)\n",
    "        ft_last = 30\n",
    "\n",
    "    elif backbone_name == \"ResNet101V2\":\n",
    "        x = layers.Lambda(resnetv2_preprocess, name=\"resnet_preprocess\")(inp)\n",
    "        base = ResNet101V2(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 90\n",
    "\n",
    "    elif backbone_name == \"EfficientNetV2S\":\n",
    "        x = layers.Lambda(effv2_preprocess, name=\"effv2_preprocess\")(inp)\n",
    "        base = EfficientNetV2S(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 140\n",
    "    elif backbone_name == \"EfficientNetV2M\":\n",
    "        x = layers.Lambda(effv2_preprocess, name=\"effv2m_preprocess\")(inp)\n",
    "        base = EfficientNetV2M(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 160   # start small; increase only if stable\n",
    "    elif backbone_name == \"DenseNet121\":\n",
    "        x = layers.Lambda(densenet_preprocess, name=\"densenet_preprocess\")(inp)\n",
    "        base = DenseNet121(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 80   # unfreeze last ~80 layers (safe start)\n",
    "\n",
    "    elif backbone_name == \"DenseNet169\":\n",
    "        x = layers.Lambda(densenet_preprocess, name=\"densenet_preprocess\")(inp)\n",
    "        base = DenseNet169(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 100  # safe start\n",
    "\n",
    "    elif backbone_name == \"DenseNet201\":\n",
    "        x = layers.Lambda(densenet_preprocess, name=\"densenet_preprocess\")(inp)\n",
    "        base = DenseNet201(include_top=False, weights=\"imagenet\")\n",
    "        feats = base(x)\n",
    "        ft_last = 120  # safe start\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown backbone\")\n",
    "\n",
    "    base.trainable = False\n",
    "    out = build_head(feats, num_classes=NUM_CLASSES)\n",
    "    model = models.Model(inp, out, name=f\"Erythema_{backbone_name}\")\n",
    "\n",
    "    fine_tune_at = max(0, len(base.layers) - ft_last)\n",
    "    return model, base, fine_tune_at\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603269f0",
   "metadata": {},
   "source": [
    "# Cell 13 â€” DenseNet Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27c3da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸš€ Training: ResNet101V2\n",
      "======================================================================\n",
      "ðŸ§© Stage 1: warmup (frozen backbone)\n",
      "Epoch 1/10\n",
      "348/348 [==============================] - 53s 123ms/step - loss: 0.8151 - accuracy: 0.5994 - val_loss: 0.7822 - val_accuracy: 0.6667 - lr: 2.0000e-04\n",
      "Epoch 2/10\n",
      "348/348 [==============================] - 59s 169ms/step - loss: 0.6245 - accuracy: 0.6980 - val_loss: 0.8820 - val_accuracy: 0.5909 - lr: 2.0000e-04\n",
      "Epoch 3/10\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.7390\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-05.\n",
      "348/348 [==============================] - 62s 179ms/step - loss: 0.5423 - accuracy: 0.7390 - val_loss: 0.9648 - val_accuracy: 0.6818 - lr: 2.0000e-04\n",
      "Epoch 4/10\n",
      "348/348 [==============================] - 78s 223ms/step - loss: 0.4988 - accuracy: 0.7649 - val_loss: 0.9732 - val_accuracy: 0.6515 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7725\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "348/348 [==============================] - 63s 182ms/step - loss: 0.4838 - accuracy: 0.7725 - val_loss: 0.9527 - val_accuracy: 0.6515 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.7815Restoring model weights from the end of the best epoch: 1.\n",
      "348/348 [==============================] - 63s 181ms/step - loss: 0.4632 - accuracy: 0.7815 - val_loss: 0.9819 - val_accuracy: 0.6364 - lr: 5.0000e-05\n",
      "Epoch 6: early stopping\n",
      "ðŸ”§ Stage 2: fine-tune (unfreeze last layers)\n",
      "Epoch 1/15\n",
      "348/348 [==============================] - 93s 239ms/step - loss: 0.6801 - accuracy: 0.6573 - val_loss: 0.8096 - val_accuracy: 0.5303 - lr: 1.0000e-05\n",
      "Epoch 2/15\n",
      "348/348 [==============================] - 86s 246ms/step - loss: 0.6084 - accuracy: 0.6865 - val_loss: 0.8244 - val_accuracy: 0.5152 - lr: 1.0000e-05\n",
      "Epoch 3/15\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.5592 - accuracy: 0.7016\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "348/348 [==============================] - 68s 194ms/step - loss: 0.5592 - accuracy: 0.7016 - val_loss: 0.8235 - val_accuracy: 0.6364 - lr: 1.0000e-05\n",
      "Epoch 4/15\n",
      "348/348 [==============================] - 69s 198ms/step - loss: 0.5235 - accuracy: 0.7307 - val_loss: 0.8482 - val_accuracy: 0.6061 - lr: 5.0000e-06\n",
      "Epoch 5/15\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4847 - accuracy: 0.7693\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "348/348 [==============================] - 76s 217ms/step - loss: 0.4847 - accuracy: 0.7693 - val_loss: 0.8784 - val_accuracy: 0.6364 - lr: 5.0000e-06\n",
      "Epoch 6/15\n",
      "348/348 [==============================] - ETA: 0s - loss: 0.4545 - accuracy: 0.7808Restoring model weights from the end of the best epoch: 1.\n",
      "348/348 [==============================] - 110s 317ms/step - loss: 0.4545 - accuracy: 0.7808 - val_loss: 0.8928 - val_accuracy: 0.6364 - lr: 2.5000e-06\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAHqCAYAAAB7pFb5AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASVBJREFUeJzt3Qd8FOX28PGzARJ6KNIUQUB6ESkCovSieBWkWWhSvIKIGEDK9aJ0EBFEERAuRb1gRVSwgBRpAlJsoERQmnSEBCkJJft+znPf3f9ustkkuMlMMr+vn5HszO7ss7OzM2fOU8bldrvdAgAAHC3M6gIAAADrERAAAAACAgAAQEAAAAAICAAAAAEBAAAwaFQIAAAICAAAAAEBAAAgIADs4cSJE9KxY0cpXLiwuFwueeWVV0L+HrreUaNGhXy9mdVjjz0mt9xyS0jXef78eSlatKgsWrQopOvNrP7880/JkyePfP7551YXBalAG4I0WLhwoTmoeqbs2bPLTTfdZA4sR44ckfSiB3F9v2LFisnFixeTLNeD2j/+8Y/rWvfMmTPN5wpk/Pjx8sADD5j3Telkop+/c+fOUqBAAcmfP7+0bdtWfv/99yTPmzVrlnTq1ElKlSpl1qnbLrEaNWqY5cFG1W7YsKEp19WrV+Xw4cMyevRoueOOO6RgwYJyww03SJMmTWTVqlWS1pPykCFDpFKlSpI7d25zIKtdu7aMGzdOYmJiJD1FRUXJihUrZMSIEfL222/LPffcI1mFZ/8NCwsz31Vi586dk1y5cpnnPPXUU2lev/4m9D2+/vprsdr06dMlX7588vDDD1tdFFvQALdPnz4ycuRIq4uC1NB7GSB1FixYoGco95gxY9xvv/22e+7cue7evXu7s2XL5i5Xrpz70qVL6bIpX3jhBfO+Ok2ZMiXJ8tKlS7vvu+++61p31apV3Y0bNw64TN+vePHi7tatW5u/tRyB/PXXX+7y5cu7ixYt6n7xxRfdU6dOdd98883ukiVLuk+fPp2krIUKFXLfc8897uzZs7t79OiRZH2TJk0y77du3bqA77d//363y+VyDxgwwDx+7bXX3Lly5XI/8sgj7hkzZrhfeeUVd61atcw65s+fn6rt8O2337pvuOEGd86cOd19+vRxz5o1y0z6/ebJk8fdsmVLd3oqVqyYu0uXLun6Hrp/XrlyxZ3RPPuvblvdPwL9rnSZPqd///5pXv+pU6eC7p/JuXz5sjsuLi7N7xdsfUWKFHFPmDAhZOvMCn7++Wfz/axevdrqoiAFBATXERBs27bNb/6wYcPM/Pfee8+dngfUmjVrmhPHxYsXMyQg0BNvag64epDX5XpS9fjll19MoDRixAi/5x44cMCdkJBg/tYTbaCA4NChQ+aE/8QTTwR8Pz3g6vtt2bLFPN61a5cpoy890FeqVMkEJSk5e/as+6abbjLbVsud2PHjx91jx451pyf9vNdzMswMPPtv+/btzT6cmAZbHTp0yLCA4Pz58+708NFHH5ly7Nu3L2TrTK+yZrRq1aq5u3XrZnUxkAKqDELg7rvvNv/+9ttvfvP37Nlj6oULFSokOXPmlDp16sinn37q95wrV66YdHf58uXNczTFdtddd8lXX32V5H2ef/55k9bWtHtKEhISTD101apVzXo1vf7EE0/I2bNn/aoadu/eLevWrfNWg2iq3Xd5anz44YdSt25dM3lo2r158+by/vvv+z23dOnS5n2Cufnmm6VRo0Zmvbp9Elu8eLGUK1dO6tWrZx7rZ9RqAl8RERHSpk0b+eOPP+Svv/4K+n5vvPGGqfKYOnWqKXdiuu3+/e9/J6lq0ffV97nxxhulf//+SaoVdFtWq1ZNfv75Z2natKmphtAqpsmTJyephtLg/PXXX/d+D76p9sQ8rzlw4IB33vbt26V169ZmO2j6vUyZMtKrVy+/1wWq9vnuu+/k3nvvNdU8efPmNd/Zli1bAr7fpk2bZNCgQVKkSBFTnfLggw/KqVOnJLUeffRR+f77783vwuP48eOyZs0asyyxy5cvm31eq20iIyPNe+pvbe3atd7n6DbQ8ij9HXm2n+dzapWUfi79ber+oOn8Ll26eJf57uMvvPCCqdZYvXq1Xzn++c9/Snh4uPzwww9BP9/HH39s1qf7pq8ff/zRvFfZsmXNb7F48eLmu9H6dV+e71v3F90eWv2lxwLP71mX676m+5HuT/o8fT/fajfPd7Vx40Z5+umnzbbRajz97ev21H20e/fuZt06DR06NEnV3JQpU+TOO+80xyLdl3T762/R14IFC8z7zJ8/32/+hAkTzPzEbQZatmwpy5YtC1oNCOsREISA58CsPzAPPdHWr19ffvnlFxk+fLi8/PLL5oDWrl07Wbp0qfd5+iPXA5n+wGfMmCHPPfecqT/fuXNnkvfRg2GzZs3MCeXSpUtBy6QHgGeffdbUtWu9Zs+ePU1DJz1peE6yGjCULFnSnAS13lonff+00AOVHvA02ElM6/T1QJzSCTkQPWjrAVPr1X399NNPsmvXLu9BPRg92ejBU6dgNEjTA58Gb6mh35kGAHpw1u+1Q4cOJqho1apVkgBGAzBtD3DbbbeZ5+q2HjZsmHzxxRdmuQY+ut09B03P95AWJ0+eNO+t+6Hua6+99prZPolP7InpPqr7lJ7o9MSg9bz79+83gczWrVuTPH/AgAHmuXri7NevnznAp6XOXz+r7m8a0Hm899575oR93333BWxb8J///MeU58UXXzTbXQMQ3Yc1sFB6wvMEyBqgeLZf+/btvevRdib6Gm3spyc7/b4C0aCvZs2a0rt3b+8+q/vf3LlzTWCi32Ew33zzjdSqVSvJfA3utT2N/gb1u9H2Be+++64JUAKdILWNjbaL0JPr448/buZp2xI9Tujv7KWXXjIXEPqZLly4ELAs+l3t3bvXvEbbAc2ZM8d8v/fff79cu3bNrFuDDV1X4v1Njxe33367jBkzxjxP20ppmT777DPvc/SzaLslDRA97UL0t6nvp9tPP5svDSo0GNF9DjaWUgoBSasMVq1aZdKUhw8fdn/44Yem3jAiIsI89mjevLm7evXqfnWUmiq/8847TX27x2233ZZiut+TctX31Hp1/Vvr6ZOrMtiwYYN5zqJFi/zW8+WXXyaZH6zKIDUpWc8ybVeR2Ouvv26W7dmzJ+B6k6syUGfOnDHbVNsF+Bo+fLhZZ3R0dNAy792719RLpyZNWbBgQfM9pMbJkyfd4eHh7latWrmvXbvmna9tFxK3WdDtqvPeeust77z4+HjTLkNT5L4Cpcs933ty+6GnSmfp0qUBq7ISS/wdtmvXznyW3377zTvv6NGj7nz58rkbNWqU5P1atGjhre5RUVFRplooJiYm1fvvkCFD3Lfeeqt3Wd26dd09e/YMuA2uXr1qtlfi6h2t2unVq1eq9k/dv3SZ7jeBlulvx9dPP/1ktom2I/FUJdWpUyfFthe6XKt9Bg8enGRZ4io+9c4775hyrV+/Psl2SrzPa5WVtrfR78vXqFGjzPN9f0Oe70rb/fh+Vw0aNDDl69u3r9/21Sq1xL//xOXVthGa8m/WrJnf/GPHjpn2QFrlo9/T7bff7i5VqpQ7NjY2yef95ptv0rVaFaFBhuA6tGjRwlyZaGpbryr1yl+vMvXqR505c8akQbXVvV5pnD592kx6xatRvUbunl4Jms7TqFnnpfYqS7MJwbIEH3zwgUmx6hWn57110ihdr8Z8U65/l6cMmjpPTNOjvs9JC8226FWGblfPVZCeM/TKSq+SKlSokOxr9epKr2j0qn/SpEkpvpdeiWoqOTW054KmXp955hmTXvbQKzlNu/teRSnd3l27dvU+1tSzZk4C9cC4XroPqeXLlwesYglErxJXrlxpMlaayvYoUaKESVdrylm3S+LUuW8VhmYXdD0HDx5MdVl13fv27ZNt27Z5/w1UXaCyZctmtpcnE6W/K73a1+8/UAYtGM1opIZW8ehVrmYm9Leqv5s333zTXCUHo2XT/dM3S+ih+6FHXFycWadmD1Wgz9G3b1+/x1qFoZ/7ySefTJIFSI5epft+V1q9puXT+b7bV7dl4n3Rt7ya4YqNjTXfdeKyatWHVnNpBkSXa9ZGqxD0d5CYZ7voZ4d9ERBcB8+PQOvV9KSlO7nvCVEPdPrj0xSdBg6+k6ZbPWlepWk5TaXpCa569eomza8p+GA0darp8NmzZwdcrsGF/og1RZr4/bWftOe9Q8Fz8IiPj0+yTA9+vs9JK017azDwySefeFOymhYPVl2gJyhNyWr9qn4/mtZPiR7AUlut4Tn5VaxY0W++nrj0xJr45KhBYuJ2AHpw9G3L8Xc1btzYpMH1RKZtCLTLp9bxBvpOPDT1roFT4s+hKleubE7AibsIalVW4s+h0vJZNBWt1SZabaBVWHpS0Wqw5OjJWLuhetrX6D6sQZfu36mlJ3NPsJ4a+hvU6oFvv/3W/F6rVKmS6tcGqgLQYGHgwIGmLYr+FvQzaBsPFehzeJZ5ePapW2+91W++tk0KFIAE+q70AkHpRUzi+Ym/Pw0sNWDRba7v4amWCVRW/a1pdY9uKw2KtQ1KsO2SUvshWCt42IuA9ArPU2euV1haF6dXOdHR0eaKUA+mSvu061VGIJ4ft17xaz27nvT0ik2vTKZNm2ZO9tp/NxB9jdarapYg8dWE0vcPNjiKpxFWKOgBQ4OhY8eOJVnmmZeak3IgWkepByw9eej21X/1qiZYH289KOkBTT97sBONLz1B6dWNXvl7rkhDRcsbSGoaVyV38NSgJ/HzNPjRNgNar6/13tpoTdss6DzdJ63+LL70u9QTjGZlHnroIb9Mi6///ve/psGc/sb0JK37tJZh4sSJSRrwBqP7Z3LvEYheMXsydlovntrfgX4PgYIjzRRqMKufQdsoeI4R2rbEc6zwdb0BdGq+q0Dzfb+/DRs2mDYHeozRhrOaMcqRI4cJMH3bfnho1lMbtCoNwvXzBNrWnu2SuPEv7IUMwd/kOUAdPXrUNApUnhSs/pC0eiHQ5Jui1oOJNtJ55513zFWZXhGlNKKcJ0ugjdkS01bO+kPVBoWB3tu3cdTfjdj1x6+ZDc9BwZc2TNNtkdp0fKADuVbJaKCkvSu0KkRP8npVGYgecPXApQHVI488kur30YZWWq2xZMmSFJ+rvSSUBn++NJjQBnme5aHgufpL3HshuRS9XtXpYFL6XWhApFVRWsWSXFCojS0Tfw6lvQD0e018NRkqGhBosPjrr78mW12gNMjR/eejjz6Sbt26meBa919P5skjlFedekLTIESzRv/617/Mb1LfPzVZCP3d6T6Q+ESoKX9t7KkZHG34qFV5vtU0KfHsU5p59KW/8VBmmpT+BjQz4AkqtQeKbvPkaONaza7pMVCrmZIbYdOzXTT7BPsiIAgBvVrXrIH+GPRgpVcyOk9P1oGunH27aiXueqRXD5o9CJbu9aSJPa2vEx8g9YpEryLHjh2b5HVaF+l7gtH2D393FD49aWtdsG9QoCcabUehdfl/h1YPaL249prQ7ZZcdYG2ltYW5HoQ1/RsWmiWRa+EBg8ebE5SiWkVi45WqPTgqFmEV1991e/Kat68eSalGqi1/PXydF9bv369d55WoWga3ZeeFBJfpeuVqEpuP9JAVnsmaGbKt/uiBl56JahZr0B1waH6XPpb0ZOI/m6S47ma9f1sGmRu3rzZ73meXiShGE1Su57q1by2ytffj3a/0/YHqan7btCgQZLAONBnUGkZmlrT8BpwJO5u7LkACSUtrwZYvlko3T+0S2WggE17iWg7HQ14NHOnPTUC/YZ27Nhhsn3aVRf2RZVBiOjVqZ78tB+wnmC0nYEeVPXqWdPYekWgB1s9mGnfeE+fZq2f1BO7NvjTTIEeUPSHlpruXFq/qQ0MAwULegLVA66mwvXAr9kKTYPqVbZ2K/J0sdP31QONnvA0ENFgxpNq1+5IejXqGS5ZT0yeE6NesXmuXLSxk3bN0pOhVpPoe+mBVetM9STrS1Pans+uJ3ptL+FZp6YqNTuS+LNo/a+euDSV6tudzEO7cWq3Oe2KpVcgmmr2pVdkWpZgV+K6Dm0PoidSbQSo20VpQyq9StSDvefK2tMFTFO+WmYNfjS9quMw+DYg/Lv0e9O6YG0IpvuXHqy10ZaW4dChQ97naYCg769Xn3qy1Ss2/T70hJ64+5cv3e7aFkb3U/0O9aSjQawGEb5jJaSH1ARtWmWkV+f6uXTf0qtMrUrT34y2hfHQ/ULn6clJ2+Lo70gbB+qUFtpFWNv9aIZAs0ZKf8+6T+j2STymRmLadkN/M3pC9DR61e9A0++6PXV/13EoNOOVOJMQjO67ur20Ckj3N93v9DekXVc1BR/KDIluZ/3t6nto9kaDYT2W6bHBt22TztdASY8/nmOVBijaYFm3n2YLfKsOdD/TbUobApsLUW8FR49UqLQLmg5frJN251Hanat79+6mm1mOHDlMF6Z//OMfpquix7hx49x33HGHu0CBAmb4XR1db/z48aarT6BuW4l5urYF6ro4Z84cd+3atc16tSuZdoMcOnSo6Vrm26VJX6vLdT2+XZA86w40rV271u+9tMtlx44d3fnz53fnzZvXfE7t+pdcN7BAk27fQJ599lmzvHPnzikO7ZyasiZHt4t2patQoYLpspg7d26z/fT7SNyVSrsZ6nel36t2g+vXr5/ppuZLt59260xNd7fkRunbsWOHu169eqYrnHbp0u6mibsd7ty503RV0+XaVVOHkNbtv3379iTvkbhrnr5Wu6jpd6aft2nTpqaLWGr2e92uqdm+wfbfYNtAu83pqJS6rfRzabe25cuXB9x+Wmb9rnQ7+X5Ofa52bw3Edz36m9UukNoNL3E3yunTp6eqy5x2vdPhrxOPavnHH3+4H3zwQfMbj4yMdHfq1Mnsa4m/j2DbScs3cuRIcyzR37N2AdRRNQsXLuzXlTC57yq5dQfaPvPmzTNdo3Wb6z6u60zcBVZHndRjho486uuTTz4xz/MdolrL6emuDXtz6f+sDkoAICvQagZtx6LZuOQa9oWKVpFodkszPWkdUCwjaRddzS5qtQEZAnujDQEAhPCulVqdkVxjzusVaCwPTzsE3+HG7UbbSGnPKQ1aCAbsjwwBANictmXQSduEaMNjraPXti3aziTx8N7A9aJRIQDYnDa21Uaf2jhRR5D0NDT0NMgFQoEMAQAAoA0BAAAgIAAAAAQEAAAgyzYqvHCZoRXgTOcupe72x0BWUyIytDcm85Xr9pRHjk2rS9+Ffujpv4txCAAAQNbMEAAAEDIuZ1w7ExAAABBMCG8gZWfOCHsAAEBQZAgAAAjGIVUGzviUAAAgKDIEAAAE45A2BAQEAAAEQ5UBAABwCjIEAAAEQ5UBAAAQqgwAAIBTUGUAAEAwDqkyYBwCAABAhgAAgKAc0oaAKgMAAIKhygAAADgFGQIAAIKhygAAAAhVBgAAwCmoMgAAIBiqDAAAgDgkIHDGpwQAAEEREAAAEEyYK/RTGtxyyy3icrmSTP379zfL4+LizN+FCxeWvHnzSocOHeTEiRNp/5hpfgUAAMgw27Ztk2PHjnmnr776yszv1KmT+TcqKkqWLVsmH3zwgaxbt06OHj0q7du3T/P70KgQAAAbtyEoUqSI3+NJkyZJuXLlpHHjxhIbGyvz5s2TxYsXS7NmzczyBQsWSOXKlWXLli1Sv379VL8PGQIAAFIahyDU03W6fPmy/Pe//5VevXqZaoMdO3bIlStXpEWLFt7nVKpUSUqVKiWbN29O07rJEAAAkMHi4+PN5CsiIsJMwXz88ccSExMjjz32mHl8/PhxCQ8PlwIFCvg9r1ixYmZZWpAhAAAgpSqDEE8TJ06UyMhIv0nnpUSrB+6991658cYbJdTIEAAAkMFDF48YMUIGDRrkNy+l7MDBgwdl1apV8tFHH3nnFS9e3FQjaNbAN0ugvQx0WVqQIQAAIIPpyT9//vx+U0oBgTYWLFq0qNx3333eebVr15YcOXLI6tWrvfOio6Pl0KFD0qBBgzSViQwBAAA2H6kwISHBBAQ9evSQ7Nn/79StVQ29e/c22YZChQqZwGLAgAEmGEhLDwNFQAAAgM1pVYFe9WvvgsSmTZsmYWFhZkAibajYunVrmTlzZprfw+V2u92SxVy4nOU+EpAq5y5dYUvBkUpEhqfbunO1nhLydV5aMUTshgwBAAA2rzLICM74lAAAICgyBAAAZHC3QzsiIAAAIBiqDAAAgFOQIQAAIBiqDAAAgFBlAAAAnIIqAwAAgiFDAAAAnIIMAQAAwdCoEAAACFUGAADAKagyAAAgGKoMAACAUGUAAACcgioDAACCocoAAAC4HBIQhFldAAAAYD2qDAAACIIMAQAAcAwyBAAABOOMJgQEBAAABEOVAQAAcAyqDAAACMIpGQICAgAAgnBKQMA4BAAAgAwBAADBkCEAAACOQRsCAACCcUYTAgICAACCocoAAAA4BlUGAAAE4ZQMAQEBAABBOCUgYBwCAABAhgAAgGCckiGgygAAgGCcEQ9QZQAAAMgQAAAQlFOqDGhUCAAAaEMAAEAwTskQ0KgQAIAgnBIQ2KLKoGzZsvLnn38mmR8TE2OWAQAAB2QIDhw4INeuXUsyPz4+Xo4cOWJJmQAAMJyRILA2IPj000+9f69YsUIiIyO9jzVAWL16tdxyyy0WlQ4AAHFMlYGlAUG7du28G7tHjx5+y3LkyGGCgZdfftmi0gEA4ByWBgQJCQnm3zJlysi2bdvkhhtusLI4AAAkQYYgA+3fvz8j3w4AgFRzUWWQsbS9gE4nT570Zg485s+fn8GlAQDAWWzRy2D06NEyZswYqVOnjpQoUcIx0RgAwP5cDjkn2SIgmD17tixcuFC6detmdVEAAHAkWwQEly9fljvvvNPqYgAAkJQzEgT2GKmwT58+snjxYquLAQBAwCqDUE92ZIsMQVxcnMyZM0dWrVolNWrUMGMQ+Jo6daplZQMAwAlsERD8+OOPUrNmTfP3rl27/JbZNZICADiDyyHnIVsEBGvXrrW6CAAAODogsEUbAo99+/aZexpcunTJPHa73VYXCQAAR7BFQKC3Pm7evLlUqFBB2rRpI8eOHTPze/fuLYMHD7a6eAAAJ3Olw2RDtggIoqKiTEPCQ4cOSe7cub3zH3roIfnyyy8tLRsAAE5gizYEK1euNFUFJUuW9Jtfvnx5OXjwoGXlAgCANgQZ6MKFC36ZAY8zZ85IREQEe6PN7Ni+TQY+1VdaNbtbalWvJGtXr/JbfvHiBZk0fozc07yxNKhzm3Roe598+P67lpUXCJVFC/8jT/R4WO5tUk/atW4szw15Wg4d/L+bs52LjZXpL02Qbh3vl1Z315HO97eUV6dMlPPn/+JLyMRcFo9DcOTIEenatasULlxYcuXKJdWrV5ft27d7l2t7u+eff94M/a/LW7RoIXv37s2cVQZ33323vPXWW97HurH0BkeTJ0+Wpk2bWlo2JBV36ZJUqFBJhj/3fMDN8/LkSfLNpo0ybtJkWfLJZ/Jo1+7y4oSxsm7tGjYnMrXvd26Xdp0elpnzFsmU1+bItWtX5dkBT8ilSxfN8tOnT8qfp09Jv4GDZcE7S2X48+Pk282bZPK4F6wuOjKps2fPSsOGDU21+hdffCE///yzvPzyy1KwYEHvc/Rc+eqrr5rbAGzdulXy5MkjrVu3NmP8pIXLbYOm/Dr2gDYqrFWrlqxZs0YeeOAB2b17t8kQbNq0ScqVK5em9V24bPlHcgzNELz8ygxp2ryFd16nB++XVq3vlcf7Pumd92jn9tLwrkbS/+lnLCqpM5y7dMXqIjhKzNkzJlMwffYCua1WnYDP+XrVChn/wgj5Yt23kj27LWpps6QSkeHptu5bBi4P+ToPTP9Hqp43fPhwcx7csGFDwOV6Cr/xxhtNA/whQ4aYebGxsVKsWDFzj6CHH344c2UIqlWrJr/++qvcdddd0rZtW1OF0L59e/nuu+/SHAzAejVuqynrvl4jJ0+cMDvrtm+3yKGDB6T+nQ2tLhoQUufPnzf/5ouMDPqc3HnyEgxkYi4Lqww+/fRTcyfgTp06SdGiReX222+XuXPnepfv379fjh8/bqoJPCIjI6VevXqyefPmNH1OW4Sr2rvg5ptvlueeey7gslKlSllSLlyfYf8aKeNGj5R7WjQ2B0Hd+UeOGiu169RlkyLL0GrNGVNflGq33S5ly5UP+JyYmLPy9vw35P52HTO8fLC3+Ph4M/nSNnOJ2839/vvvMmvWLBk0aJD861//km3btsnTTz8t4eHh0qNHDxMMKM0I+NLHnmWZKiAoU6aMGXtAo5/E4xPosmvXrqVpo151hdMY0ULvLn5bfvrxB5n22kwpUeIm2bljm2lkWKRIUanXgLtaImt4ZfJ42f/7PnltzpsBl184f15GRPWX0mXKymP/7Jfh5UMIuUK/NSdOnCijR4/2m/fCCy/IqFGjkgSemiGYMGGCeawZAq1m1/YCGhCEki2qDDStHCiFoqm2nDlzprhRNT3iO02ZPDEdS4tgtBHLjOmvyKBnh0vjJs2kQsWK8vCjXaXVPW3krTfns/GQJbzy0njZvHGdvDJznhQtVjzJ8osXLsjQgX0lV+7cMnbydMme3f+GbchcXOlQZTBixAhT1+876bzEtOdAlSpV/OZVrlzZZM9V8eL/2/9OnDjh9xx97FmWKTIEmgJRJqU8cqRf10PNCmhrSc9Nj5KjG9CzHt8MAaxx9epVuXr1ioS5/GPNsLAwcSck8LUgU9OLl+lTJsjGr9fIK7PmS4mb/MdO8WQGnn36CckRHi4TXn6NbCUCClQ9EIj2MIiOjvabp23uSpcubf7WLLqe+FevXu09X547d86cP/v165d5AgJtNOj5kf3000+mTsRD/77tttu8rSbTslHpZZC+dJyBw/8/OlVHjvwh0Xt+kfyRkVKixI2mrcArU1+SiJwRpspgx/Zv5bNln5isAZDZqwlWrfhcxk+ZLrly55E/T5828/PmzSsROXOaYGDI009IfNwleW7MJLlw/oKZVIGCBSVbtmwWfwJktoGJoqKi5M477zRVBp07d5Zvv/1W5syZYyZP2Z555hkZN26cGcxPAwS9wNaeB+3atct83Q579uwp06dPl/z584dkfQQE6Wv7tq3yz15J667uf6CdjB4/SU6fPiWvvTJVtmzeZAZq0SChfcfO0qX7Y44Z8csqdDtMX03uqB5w/rDnx8q9/2gn3+3YJlH9egV8zjsffyklbrwpnUvoXOnZ7bDc4C9Cvs7fXr431c9dvny5yYbrYEN6wtes+OOPP+5drqdxbX+gQUJMTIzpsTdz5kxzf6BMFxAkpukOHY+gUqVKZkorAgI4FQEBnCo9A4Jbh4Q+INg3JfUBQUaxRaNCTYPMmDHD/K23PtYWlTpPh2dcsmSJ1cUDADiYy+Khix0VEKxfv94MX6yWLl1q0h+a9tChGLVeBAAAOCAg0O4WhQoVMn/r7Y47dOhgehzcd99913WDBgAAQsXlCv1kR7YICHSUQh1iUYcs1oCgVatW3ps6pDQOAQAA6cnlkCoDW4xUqF0munTpYrruaN/KJk2aeKsStB0BAABwQEDw5JNPyh133CGHDx+Wli1bmkFsVNmyZWlDAACwlMueF/RZMyBQ2rNAJ1/ahgAAACuFhTkjIrAsINCBFcaOHSt58uRJMvRwYlOnTs2wcgEA4ETZrRy2+MqVK96/k2PXxhcAAGdwOeQ0ZFlAsHbt2oB/AwAAh3Y7PHXqVLLL9KZHAABYxeWQboe2CAi0a+Fnn32WZP6UKVNM7wMAAKziYmCijKONCnV0Qr13s97L4MiRI9K8eXOZPHmyLF68OANLAgCAM9mi2+HQoUPN+APdunWTGjVqyJkzZ6RevXry448/SvHixa0uHgDAwVw2TfFnySoDdeutt0q1atXkwIED5vbHDz30EMEAAMByLtoQZJxNmzaZzIDeyEizArNmzZIBAwaYoEDvZwAAAByQIWjWrJk5+W/ZskUqV64sffr0MWMTHDp0iHsZAAAs5XJIo0JbtCFYuXKlNG7c2G9euXLlTOZg/PjxlpULAACnsDRD0KZNG4mNjfUGA5MmTZKYmBjvcq0ueOeddywsIQDA6Vy0IUh/K1askPj4eO/jCRMmmB4GHlevXpXo6OgMKAkAAM6uMrA0Q+B2u4M+BgAADmpDAACAXbnsekmflQKCQGM6O2XDAwAyB5dDTkuWBgRaRfDYY49JRESEeRwXFyd9+/aVPHnymMe+7QsAAEAWDQh69Ojh97hr165JntO9e/cMLBEAAOLIzLWlAcGCBQusfHsAAFLkckY8YI+RCgEAgLXoZQAAQBBOqTIgQwAAAMgQAAAQjEMSBAQEAAAEQ5UBAABwDBoVAgAQBFUGAABAqDIAAACOQZUBAABBOKXKgHEIAAAAGQIAAIJxShsCqgwAAAjCKQEBVQYAAIAMAQAAwTgkQUBAAABAMFQZAAAAx6BRIQAAQVBlAAAAhCoDAADgGFQZAAAQhFOqDBiHAAAAkCEAACCYMIekCKgyAAAgCIfEA1QZAAAAMgQAAATllG6HVBkAABBEmDPiAaoMAAAAGQIAAIKiygAAAIhDmhBQZQAAAKgyAAAgKJc4I0XA0MUAAIBuhwAABEO3QwAAINrLINRTao0aNSrJaytVquRdHhcXJ/3795fChQtL3rx5pUOHDnLixInr+taoMgAAwMaqVq0qx44d804bN270LouKipJly5bJBx98IOvWrZOjR49K+/btr+t9GKkQAAAbdzvMnj27FC9ePMn82NhYmTdvnixevFiaNWtm5i1YsEAqV64sW7Zskfr166fpfcgQAACQwu2PQz2lxd69e+XGG2+UsmXLSpcuXeTQoUNm/o4dO+TKlSvSokUL73O1OqFUqVKyefNmSSsyBAAAZLD4+Hgz+YqIiDCTr3r16snChQulYsWKprpg9OjRcvfdd8uuXbvk+PHjEh4eLgUKFPB7TbFixcyytCJDAABAEHpBH+pp4sSJEhkZ6TfpvMTuvfde6dSpk9SoUUNat24tn3/+ucTExMj7778voUZAAABABhsxYoRpA+A76byUaDagQoUKsm/fPtOu4PLlyyZA8KW9DAK1OUgJAQEAABnc7VCrBvLnz+83Ja4uCOT8+fPy22+/SYkSJaR27dqSI0cOWb16tXd5dHS0aWPQoEEDSSvaEAAAYNNeBkOGDJH7779fSpcubboUvvDCC5ItWzZ55JFHTDVD7969ZdCgQVKoUCETVAwYMMAEA2ntYaAICAAAsKk//vjDnPz//PNPKVKkiNx1112mS6H+raZNmyZhYWFmQCJtpKjtDGbOnHld7+Vyu91uyWIuXM5yHwlIlXOXrrCl4EglIsPTbd0PvfldyNf5Xo/bxW7IEAAAEIQz7nVIo0IAAECGAACA4NJyM6LMjCoDAACC4PbHAADAMcgQAAAQhFOqDBipEAAAkCEAACAYhyQICAgAAAiGKgMAAOAYNCoEACAIp3Q7JCAAACAIqgyC2LBhg3Tt2tXcYvHIkSNm3ttvvy0bN24M9jIAAJBVuh0uWbLE3F4xV65c8t1335nbLarY2FiZMGFCepQRAADLuNJhyhIBwbhx42T27Nkyd+5cyZEjh3d+w4YNZefOnaEuHwAAlgpzuUI+ZYmAIDo6Who1apRkfmRkpMTExISqXAAAwM4BQfHixWXfvn1J5mv7gbJly4aqXAAA2ILLFfopSwQEjz/+uAwcOFC2bt1qWl4ePXpUFi1aJEOGDJF+/fqlTykBAIC9uh0OHz5cEhISpHnz5nLx4kVTfRAREWECggEDBqRPKQEAsIjLrpf0IeZyu93u63nh5cuXTdXB+fPnpUqVKpI3b16xiwuXr+sjAZneuUtXrC4CYIkSkeHptu4nPtwd8nW+0bGqZJmBicLDw00gAAAAMr80BwRNmzYNmj5Zs2bN3y0TAAC2EeaQKoM0BwQ1a9b0e3zlyhX5/vvvZdeuXdKjR49Qlg0AAMu5nBEPpD0gmDZtWsD5o0aNMu0JAABA5pPmbofJ0XsbzJ8/P1SrAwDAFlwuV8inLB0QbN68WXLmzBmq1QEAADtXGbRv397vsfZaPHbsmGzfvl1GjhwpdpDNKTevBhIp22QQ2wSOdOm7Gfa/cs5qAYHes8BXWFiYVKxYUcaMGSOtWrUKZdkAALCcy6YpfksDgmvXrknPnj2levXqUrBgwfQrFQAAyFBpyoRky5bNZAG4qyEAwCnCXKGf7CjNVSPVqlWT33//PX1KAwCAzYQREAQ2btw4cyOj5cuXm8aE586d85sAAEAWbkOgjQYHDx4sbdq0MY8feOABv4YW2ttAH2s7AwAAsgoXjQr9jR49Wvr27Str16616CsBACDjhdm0zt+yDIHnLsmNGzdOz/IAAAC7dzt0StoEAAAPp5z60hQQVKhQIcWg4MyZM3+3TAAAwM4BgbYjSDxSIQAAWVmYQ1IEaQoIHn74YSlatGj6lQYAAJsJE2dI9eek/QAAAFlXmnsZAADgJC5n1BikPiBISEhI35IAAGBDYQ6JCJxSNQIAAELVqBAAAKdxOSNBQEAAAEAwThm6mCoDAABAhgAAgGBoVAgAAByDRoUAAARBo0IAACA0KgQAAI5BlQEAAEG4xBn9DgkIAAAIgioDAADgGGQIAAAIggwBAABwDDIEAAAE4XLIQAQEBAAABEGVAQAAcAwyBAAABOGQGgNufwwAQEp3Owz1dL0mTZpk2jQ888wz3nlxcXHSv39/KVy4sOTNm1c6dOggJ06cSPO6w667VAAAIMNs27ZN3njjDalRo4bf/KioKFm2bJl88MEHsm7dOjl69Ki0b98+zesnIAAAIIVGhaGe0ur8+fPSpUsXmTt3rhQsWNA7PzY2VubNmydTp06VZs2aSe3atWXBggXyzTffyJYtW9L0HgQEAAAEoRn+UE9ppVUC9913n7Ro0cJv/o4dO+TKlSt+8ytVqiSlSpWSzZs3p+k9aFQIAEAGi4+PN5OviIgIMyX27rvvys6dO02VQWLHjx+X8PBwKVCggN/8YsWKmWVpQYYAAIAgwsQV8mnixIkSGRnpN+m8xA4fPiwDBw6URYsWSc6cOSU9kSEAACCDjRgxQgYNGuQ3L1B2QKsETp48KbVq1fLOu3btmqxfv15mzJghK1askMuXL0tMTIxflkB7GRQvXjxNZSIgAAAgg8chSK56ILHmzZvLTz/95DevZ8+epp3AsGHD5Oabb5YcOXLI6tWrTXdDFR0dLYcOHZIGDRqkqUwEBAAA2HTo4nz58km1atX85uXJk8eMOeCZ37t3b5NtKFSokOTPn18GDBhggoH69eun6b0ICAAAyMSmTZsmYWFhJkOgDRVbt24tM2fOTPN6XG632y1ZTNxVq0sAWKNg3afY9HCkS9/NSLd1z9lyMOTr/Gf90mI3ZAgAAAiCexkAAADHIEMAAEAQf+dmRJkJAQEAAEE4JB5gpEIAAECGAACAoJwyxr9TPicAAAiCNgQAAAThckgjAgICAACCcEY4QJUBAAAgQwAAQHCMQwAAAIQqAwAA4Bg0KgQAIAiHdDJgHAIAAGCTgKBs2bLy559/JpkfExNjlgEAYOU4BK4QT3ZkiyqDAwcOyLVr15LMj4+PlyNHjlhSJgAAbHPlnNUDgk8//dT794oVKyQyMtL7WAOE1atXyy233GJR6QAAcA5LA4J27dqZfzV90qNHD79lOXLkMMHAyy+/bFHpAAAQ26b4s1RAkJCQYP4tU6aMbNu2TW644QYriwMAQBLOCAds0oZg//79VhcBAABHs0VAoLS9gE4nT570Zg485s+fb1m5AADO5qLKIOOMHj1axowZI3Xq1JESJUo4ZuMDAOwvTJzBFhmC2bNny8KFC6Vbt25WFwUAAEeyRUBw+fJlufPOO60uBgAASTgla22LTEifPn1k8eLFVhcDAADHskWGIC4uTubMmSOrVq2SGjVqmDEIfE2dOtWysgEAnM0lzmCLgODHH3+UmjVrmr937drlyFQNAMCeXA45DdkiIFi7dq3VRQAAwNFs0YbAY9++feaeBpcuXTKP3W631UUCADhcmLhCPtmRLQICvfVx8+bNpUKFCtKmTRs5duyYmd+7d28ZPHiw1cUDADi8ysAV4smObBEQREVFmYaEhw4dkty5c3vnP/TQQ/Lll19aWjYAAJzAFm0IVq5caaoKSpYs6Te/fPnycvDgQcvKBQCAy6Yp/iyZIbhw4YJfZsDjzJkzEhERYUmZAABwElsEBHfffbe89dZbfl0N9QZHkydPlqZNm1paNgCAs7kc0obAFlUGeuLXRoXbt283wxgPHTpUdu/ebTIEmzZtsrp4AAAHC6PKIONUq1ZNfv31V7nrrrukbdu2pgqhffv28t1330m5cuUysCQAADiTLTIE2rvg5ptvlueeey7gslKlSllSLgAAXDZN8WfJNgRlypSRU6dOBRyfQJcBAGAVl0PaENgiINARCQPds+D8+fOSM2dOS8oEAICTWFplMGjQIPOvBgMjR47063p47do12bp1q/emRwAAWMHlkEaFlgYE2mjQkyH46aefJDw83LtM/77ttttkyJAhFpYQAOB0Yc6IB6wNCDx3OezZs6dMnz5d8ufPb2VxAABwLFv0MliwYIHf43PnzsmaNWukUqVKZgIAwCouh1QZ2KJRYefOnWXGjBnmb731cZ06dcy86tWry5IlS6wuHgAAWZ4tAoL169eb4YvV0qVLTZuCmJgYefXVV2XcuHFWFw8A4GAuuh1mnNjYWClUqJD5W2933KFDB9Pj4L777pO9e/dmYEkAAEhaZRDq/+zIFhkCHaVw8+bNZshiDQhatWpl5p89e5ZxCAAAcEqjwmeeeUa6dOkiefPmldKlS0uTJk28VQnajgAAAKuE2fOCPmsGBE8++aTccccdcvjwYWnZsqWEhf0vcVG2bFnaEAAALOWyaYo/SwYESnsW6ORL2xDAfnZs3yYL58+TX37eZe5BMe3V16VZ8xbe5bdVrRjwdVGDn5XHevXJwJICobXns9FS+sbCSebPfm+9RE1632/exzP6SeuGVaVz1BxZ9vWPfBWwvexWDls8duxYyZMnj3cI4+RMnTo1w8qFlF26dFEqVqwo7dp3kEEDn0qyfPXXG/0eb9y4XkaNfE5atGzN5kWmdlfXlySbT/64yq03yuezB8hHX/1v1FWPAV2aitttQQGRLlzOSBBYFxDosMVXrlzx/p2cQDc9grXuuruxmZJzQ5Eifo+/XrNa6t5RT0refHMGlA5IP6fPnvd7PKRnNfnt0CnZsOP/ekPVqHCTDOzWTBp2mSwHVk3k68gCXOIM2a0etjjx38ha/jx9WjasXydjx0+yuihASOXInk0eblNXXv3vGu+8XDlzyMKJj8kzk96XE3/+xRZHpmKLbodaD50cvekRMq9PP1kquXPnkeYt/9eVFMgqHmhaQwrkyyX/XbbVO2/y4A6y5Yf9svxrjltZSZjLFfLJjmwREGjXws8++yzJ/ClTppjeB8HEx8ebex/4TjoP9vDx0iXS5h/3S0REhNVFAUKqR7s7ZcWmn+XYqVjz+L7G1aXJHRXk2Zc+ZEsjU7JFQKCNCnV0wn79+pl7GRw5ckSaN28ukydPlsWLFwd97cSJEyUyMtJveulF6u3sYOeO7XJg/35p36GT1UUBQqpUiYLSrF5FWfjxN955TepWkLIlb5Dj61+Sv7ZNN5N6Z0ofWTF3IN9AJuZKh8mObNHtcOjQoWb8gW7dukmNGjXkzJkzUq9ePfnxxx+lePHiQV87YsSIJL0U3Nm4GrWDpUs+lCpVq0pF7liJLKbbAw3k5Jm/5IsNu73zpixYKQuW/l+AoHZ8+JwMfXmJfLZulwWlRMi4nLEtbREQqFtvvVWqVavmvbvhQw89lGIwoDQVnTgdHXc13YoJEbl44YIcOnTIuy2O/PGH7PnlF5OdKXHjjWbe+fPnZeXKL2Xws8PYZshStOdT97b1ZdHyrXLtWoJ3vjYiDNSQ8PCxs3Lw6J8ZXEogkwYEmzZtkq5du5obHGlWQB8PGDBAPv/8c5k9e7YULFjQ6iLCx+7du6RPz+7ex1Mm/6+K5oG2D8rYCf/rTfDl55+JdsS+t80/2HbIUrSqoFSJQvLmx1usLgoyiMshKQKXW+81bDG9wo+KijIDFeXIkcPM++2330yQoMMZ//HHH2laHxkCOFXBukkHigKc4NJ3M9Jt3d/+/r+Go6F0R9nIVD1v1qxZZjpw4IB5XLVqVXn++efl3nvvNY/j4uJk8ODB8u6775oG9a1bt5aZM2dKsWLFMmejwpUrV8qkSZO8wYAqV66cyRQ88cQTlpYNAACrlCxZ0pwfd+zYIdu3b5dmzZpJ27ZtZffu/7Vf0YvpZcuWyQcffCDr1q2To0ePSvv27TNvhsBj3759JjPQqFEjyZUrl2jRrmekQjIEcCoyBHCq9MwQbEuHDEHdVGYIAtHq9Zdeekk6duwoRYoUMb3x9G+1Z88eqVy5smzevFnq16+f+TIEf/75p+lmWKFCBWnTpo0cO3bMzO/du7cMGTLE6uIBABBS1zOGzrVr10zVwIULF6RBgwYma6C3AGjR4v9uLlepUiUpVaqUCQjSyhYBgaY8tLpAW67nzp3bO197GnzxxReWlg0A4HCu0E+BxtDRecmN2Js3b17T3q5v376ydOlSqVKlihw/flzCw8OlQIECfs/X9gO6LFP2MtA2BCtWrDB1Jb7Kly8vBw8etKxcAAC40qGXQaAxdJIb0VXvLvv9999LbGysfPjhh9KjRw/TXiDUbBEQaPrDNzPgoQMUMeQtACCriQgwhk5yNAugY/Wo2rVry7Zt22T69Okmi3758mWJiYnxyxKcOHEiVeP42LLK4O6775a33nrL+1gbEiYkJJihi5s2bWpp2QAAzuZyhX76O/T8qO0NNDjQ6vbVq1d7l0VHR5vqd21jkCkzBHri10aF2qVCox0dyli7VGiGQLseAgBgFZeFm16rFnTMAW0o+Ndff5keBV9//bWpZtd2B9r4XqsetOdB/vz5zaB+GgyktYeBbQICHbL4119/lRkzZki+fPnMsLfaj7J///5SokQJq4sHAIAlTp48Kd27dze97zQA0Pv9aDCg9/9R06ZNk7CwMHODQN+BiTL9OAShwjgEcCrGIYBTpec4BDsPngv5OmuVzi92Y4s2BL6qV69uhisGAMAuvQxcIf7PjmwXEOh4zTrQAgAAyDi2aEMAAIBduex5QZ/1MwTaBVHvYwAAABycIfj888+tLgIAAF4OSRDYJyDYu3evrF271nSx0EEXfOm9nwEAsITLGdvdFgHB3LlzpV+/fnLDDTeY4RZ9b3msfxMQAADggIBg3LhxMn78eBk2bJjVRQEAwI9duwlmyYDg7Nmz0qlTJ6uLAQBAEvQyyEAaDOgtkAEAgIMzBHpbx5EjR8qWLVvMSIV69yZfTz/9tGVlAwA4m0ucwRb3MihTpkyyy7RR4e+//56m9XEvAzgV9zKAU6XnvQx2HTkf8nVWuymv2I0tMgT79++3uggAADiaLQICX56EhW/XQwAArOKUXga2Gbr4rbfeMu0HdNhinfSez2+//bbVxQIAwBFskSGYOnWqaVT41FNPScOGDc28jRs3St++feX06dMSFRVldREBAA7lckaCwB4BwWuvvSazZs2S7t27e+c98MADUrVqVRk1ahQBAQDAMi6HbHtbVBkcO3ZM7rzzziTzdZ4uAwAADggIdByC999/P8n89957T8qXL29JmQAA8KYIQj3ZkC2qDEaPHi0PPfSQrF+/3tuGYNOmTbJ69eqAgQIAABnFZdczeFbMEHTo0EG2bt0qhQsXlo8//thMeufDb7/9Vh588EGriwcAQJZniwyBql27tixatMjqYgAA4IdeBhkgLCwsxQGIdPnVq1czojgAADiWpRmCpUuXJrts8+bN8uqrr0pCQkKGlgkAAF/OaEFgcUDQtm3bJPOio6Nl+PDhsmzZMunSpYuMGTPGkrIBAOCkiMAWjQrV0aNH5fHHHzfDF2sVwffffy9vvvmmlC5d2uqiAQCQ5VkeEMTGxsqwYcPMWAS7d+82XQ01O1CtWjWriwYAgLjS4T87srTKYPLkyfLiiy9K8eLF5Z133glYhQAAgJVc9jx/h5zL7bnfsEW9DPTOhi1atJBs2bIl+7yPPvooTeuNo1MCHKpg3aesLgJgiUvfzUi3de87eSnk67y1aC6xG0szBHozo5S6HQIAYCWXQza/pQHBwoULrXx7AABS5nLGRrK8USEAALCebYYuBgDAjlwOSRGQIQAAAGQIAAAIxilt36kyAAAgCIfEA1QZAAAAMgQAAATnkBQBVQYAAARBLwMAAOAYZAgAAAiCXgYAAEAc0oSAXgYAAIAqAwAAgnJKlQFDFwMAABoVAgAQnDNSBPQyAAAgCKoMAACAY5AhAABAnF5hQEAAAEBQVBkAAADHoMoAAIAguLkRAABwDDIEAAAE45BWhQQEAAAE4ZB4gKGLAQAAGQIAAIJySrdDqgwAAAiCXgYAAMAxyBAAABCMQ6oMwqwuAAAAdo8HXCGeUmvixIlSt25dyZcvnxQtWlTatWsn0dHRfs+Ji4uT/v37S+HChSVv3rzSoUMHOXHiRJo/JwEBAAA2tW7dOnOy37Jli3z11Vdy5coVadWqlVy4cMH7nKioKFm2bJl88MEH5vlHjx6V9u3bp/m9XG632y1ZTNxVq0sAWKNg3afY9HCkS9/NSLd1/3kh9CeVwnmur8b+1KlTJlOgJ/5GjRpJbGysFClSRBYvXiwdO3Y0z9mzZ49UrlxZNm/eLPXr10/1uskQAACQweLj4+XcuXN+k85LiQYAqlChQubfHTt2mKxBixYtvM+pVKmSlCpVygQEaUFAAABACt0OQ/2ftg2IjIz0m3ReMAkJCfLMM89Iw4YNpVq1ambe8ePHJTw8XAoUKOD33GLFipllaUEvAwAAMnhgohEjRsigQYP85kVERAR9jbYl2LVrl2zcuDH0BSIgAAAg4+nJP6UAwNdTTz0ly5cvl/Xr10vJkiW984sXLy6XL1+WmJgYvyyB9jLQZWlBlQEAADal7f41GFi6dKmsWbNGypQp47e8du3akiNHDlm9erV3nnZLPHTokDRo0CBN70WVAQAANr2XgVYTaA+CTz75xIxF4GkXoG0OcuXKZf7t3bu3qX7Qhob58+eXAQMGmGAgLT0MFAEBAAA2NWvWLPNvkyZN/OYvWLBAHnvsMfP3tGnTJCwszAxIpD0VWrduLTNnzkzzezEOAZCFMA4BnCo9xyGIvZQQ8nVG5rJfjb39SgQAADIcVQYAANi0DUFGIiAAACAIh8QDVBkAAAAyBAAABOeQFAFVBgAABKH3HnACehkAAAAyBAAABEMvAwAAIM6oMKDKAAAA0KgQAIAUOCRFQKNCAABAo0IAAIJxSrdDxiEAACAIp/QyoMoAAACIy+12u9kOCJX4+HiZOHGijBgxQiIiItiwcAT2e2QFBAQIqXPnzklkZKTExsZK/vz52bpwBPZ7ZAVUGQAAAAICAABAQAAAAAgIEGrakPCFF16gQSEchf0eWQGNCgEAAG0IAAAAAQEAACAgQGo1adJEnnnmGTYYkEb8dpBZMA6BQzz22GPicrmSTPfcc0+qXv/RRx/J2LFjLT8Aapk//vjjdFk37L3vTpo0yW++7gc63+747SCz4OZGDqIn/wULFvjNS+3wwoUKFUqnUgEpy5kzp7z44ovyxBNPSMGCBTPVJuO3g8yCDIGD6Mm/ePHifpMeXL/++msJDw+XDRs2eJ87efJkKVq0qJw4cSLgVf/MmTOlfPny5kBdrFgx6dixo/dqbt26dTJ9+nRvFuLAgQNm2a5du+Tee++VvHnzmtd069ZNTp8+7V2nvsfTTz8tQ4cONQdRLd+oUaO8y2+55Rbz74MPPmjW63mMrK9FixZmf9D7ZCRnyZIlUrVqVbOf677x8ssv+y3XeRMmTJBevXpJvnz5pFSpUjJnzpwU3zvYfstvB1mK3twIWV+PHj3cbdu2TXb5s88+6y5durQ7JibGvXPnTnd4eLj7k08+8S5v3Lixe+DAgebvbdu2ubNly+ZevHix+8CBA+b506dPN8v09Q0aNHA//vjj7mPHjpnp6tWr7rNnz7qLFCniHjFihPuXX34xr2nZsqW7adOmfu+RP39+96hRo9y//vqr+80333S7XC73ypUrzfKTJ0/qjbjcCxYsMOvVx3DOvvvRRx+5c+bM6T58+LCZv3TpUrM/qO3bt7vDwsLcY8aMcUdHR5t9JFeuXOZfD92/CxUq5H799dfde/fudU+cONG8Zs+ePcm+d2r2W347yCoICBx0UNWTeJ48efym8ePHm+Xx8fHumjVrujt37uyuUqWKOaH78g0IlixZYk7c586dC/hevs/1GDt2rLtVq1Z+8/TArgd0PYB7XnfXXXf5Padu3bruYcOGeR/r8/VEAGcGs/Xr13f36tUrSUDw6KOPmhO1Lz1R677sGxB07drV+zghIcFdtGhR96xZs5J979Tst/x2kFVQZeAgTZs2le+//95v6tu3r1mmVQaLFi0yade4uDiZNm1asutp2bKllC5dWsqWLWvSp/q6ixcvBn3vH374QdauXWvSrp6pUqVKZtlvv/3mfV6NGjX8XleiRAk5efLk3/zkyCq0HcGbb74pv/zyi998fdywYUO/efp47969cu3atYD7l1Y7aTWEZ//yVAvopFUPqd1v+e0gq6BRoYPkyZNHbr311mSXf/PNN+bfM2fOmEmfH4jWv+7cudPUn65cuVKef/55U9e/bds2KVCgQMDXnD9/Xu6//35zQE9MT/oeOXLk8FumB+2EhIRUf0ZkbY0aNZLWrVvLiBEjTHuVtAq2f/3nP/+RS5cu+T0vtfstvx1kBQQE8F7tREVFydy5c+W9996THj16yKpVqyQsLHASKXv27Kahl0567wINBNasWSPt27c3V0y+V2WqVq1aJvugDbv0tddLD9SJ1w1n0e6HNWvWlIoVK3rnVa5cWTZt2uT3PH1coUIFyZYtW6rWe9NNNyWZl5r9lt8OsgqqDBwkPj5ejh8/7jdpa2k9wXbt2tVcefXs2dN0Tfzxxx+TtNL2WL58ubz66qumyuHgwYPy1ltvmasszwFaD55bt241vQt0/bqsf//+JuvwyCOPmEyCHkRXrFhh3i8tJ3hd9+rVq03Zz549G7Jtg8yjevXq0qVLF7MPegwePNjsFzpWxq+//mqqFWbMmCFDhgz5W++V0n7LbwdZCQGBg3z55Zcmzek73XXXXTJ+/HhzYn/jjTfM83S+dsf697//bepQE9NsgA620qxZM3NlNnv2bHnnnXe89a56ENarsipVqkiRIkXk0KFDcuONN5orNj2AtmrVyhzUtRujriu5LEQgGqR89dVXcvPNN8vtt98ewq2DzGTMmDF+VUl6Jf/+++/Lu+++K9WqVTPVWPqc66lW8JXSfstvB1kJdzsEAABkCAAAAAEBAAAgIAAAAAQEAADAoJcBAAAgIAAAAAQEAACAgAAAABAQAJmYjsLXrl077+MmTZqYUfQymt7kSm8SFBMTk+HvDSB0aFQIpMOJWk+QOumNnvQOkzqM7tWrV9N1W+tw0jqWf2pwEgeQGHc7BNLBPffcY24SpTeU+vzzz81NcvROjXrbXl+XL182QUMoFCpUKCTrAeBMZAiAdBARESHFixeX0qVLS79+/cxtoj/99FNvml9viqM3zvHcIfLw4cPSuXNnc9McPbG3bdvW3C3SQ2+uM2jQILO8cOHCMnToUHG73X7vmbjKQIORYcOGmRtBaXk0UzFv3jyz3qZNm5rnFCxY0GQyPDcB0hsGTZw4UcqUKSO5cuWS2267TT788EO/99EAR28rrMt1Pb7lBJB5ERAAGUBPnpoNUHqb3ujoaHPXRr2V9JUrV8ytp/PlyycbNmwwd9fLmzevyTJ4XqN3eVy4cKHMnz9fNm7caG7Ju3Tp0qDv2b17d3MXSr1N8C+//GLuZqnr1QBhyZIl5jlajmPHjsn06dPNYw0G9HbWegfL3bt3S1RUlLk19rp167yBS/v27eX+++83t7/u06ePDB8+PJ23HoAM4QYQUj169HC3bdvW/J2QkOD+6quv3BEREe4hQ4aYZcWKFXPHx8d7n//222+7K1asaJ7roctz5crlXrFihXlcokQJ9+TJk73Lr1y54i5ZsqT3fVTjxo3dAwcONH9HR0dr+sC8dyBr1641y8+ePeudFxcX586dO7f7m2++8Xtu79693Y888oj5e8SIEe4qVar4LR82bFiSdQHIfGhDAKQDvfLXq3G9+tc0/KOPPiqjRo0ybQmqV6/u127ghx9+kH379pkMga+4uDj57bffJDY21lzF16tXz7sse/bsUqdOnSTVBh569Z4tWzZp3LhxqsusZbh48aK0bNnSb75mKW6//Xbzt2YafMuhGjRokOr3AGBfBARAOtC69VmzZpkTv7YV0BO4R548efyee/78ealdu7YsWrQoyXqKFCly3VUUaaXlUJ999pncdNNNfsu0DQKArI2AAEgHetLXRnypUatWLXnvvfekaNGikj9//oDPKVGihGzdulUaNWpkHmsXxh07dpjXBqJZCM1MaN2/NmhMzJOh0MaKHlWqVDEn/kOHDiWbWahcubJpHOlry5YtqfqcAOyNRoWAxbp06SI33HCD6VmgjQr3799vxgl4+umn5Y8//jDPGThwoEyaNEk+/vhj2bNnjzz55JNBBwK65ZZbpEePHtKrVy/zGs8633//fbNcez9o7wKt2jh16pTJDmiVxZAhQ0xDwjfffNNUV+zcuVNee+0181j17dtX9u7dK88++6xpkLh48WLT2BFA5kdAAFgsd+7csn79eilVqpRpwa9X4b179zZtCDwZg8GDB0u3bt3MSV7r7PXk/eCDDwZdr1ZZdOzY0QQPlSpVkscff1wuXLhglmmVwOjRo00PgWLFislTTz1l5uvARiNHjjS9DbQc2tNBqxC0G6LSMmoPBQ0ytEui9kaYMGFCum8jAOnPpS0LM+B9AACAjZEhAAAABAQAAICAAAAAEBAAAAACAgAAYNCoEAAAEBAAAAACAgAAQEAAAAAICAAAgEGjQgAAQEAAAIBA/h95deBwMwvGHAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 550x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Existent       0.51      0.45      0.48        40\n",
      "Non-existent       0.77      0.81      0.79        91\n",
      "\n",
      "    accuracy                           0.70       131\n",
      "   macro avg       0.64      0.63      0.64       131\n",
      "weighted avg       0.69      0.70      0.70       131\n",
      "\n",
      "âœ… ResNet101V2 | Argmax ACC=0.7023 F1W=0.6963\n",
      "âœ… ResNet101V2 | Best t=0.37 -> TEST ACC=0.6718 F1W=0.6821\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "name = \"DenseNet121\"\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸš€ Training:\", name)\n",
    "print(\"=\"*70)\n",
    "\n",
    "model, base, fine_tune_at = make_model(name)\n",
    "\n",
    "print(\"ðŸ§© Stage 1: warmup (frozen backbone)\")\n",
    "fit_model(model, epochs=10, lr=2e-4)\n",
    "\n",
    "print(\"ðŸ”§ Stage 2: fine-tune (unfreeze last layers)\")\n",
    "base.trainable = True\n",
    "for layer in base.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "freeze_bn(model)\n",
    "fit_model(model, epochs=15, lr=8e-6)   # DenseNet usually likes slightly smaller LR\n",
    "\n",
    "acc_arg, f1_arg, y_true, y_pred, _ = eval_on_test(model)\n",
    "show_confusion(y_true, y_pred, f\"{name} Confusion Matrix (argmax)\")\n",
    "\n",
    "best_t, best_val_f1 = best_threshold_on_val(model)\n",
    "acc_thr, f1_thr, y_true_t, y_pred_t = eval_threshold(model, best_t)\n",
    "\n",
    "results.append({\n",
    "    \"Model\": name,\n",
    "    \"Argmax_ACC\": acc_arg,\n",
    "    \"Argmax_F1W\": f1_arg,\n",
    "    \"Best_t(VAL)\": best_t,\n",
    "    \"Test_ACC@t\": acc_thr,\n",
    "    \"Test_F1W@t\": f1_thr\n",
    "})\n",
    "\n",
    "print(f\"âœ… {name} | Argmax ACC={acc_arg:.4f} F1W={f1_arg:.4f}\")\n",
    "print(f\"âœ… {name} | Best t={best_t:.2f} -> TEST ACC={acc_thr:.4f} F1W={f1_thr:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb40e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved + cleared session for ResNet101V2\n"
     ]
    }
   ],
   "source": [
    "# âœ… save the trained model (best)\n",
    "model.save(f\"{name}_erythema.keras\")\n",
    "\n",
    "# or weights only (lighter)\n",
    "# model.save_weights(f\"{name}_erythema.weights.h5\")\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "print(f\"âœ… Saved + cleared session for {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c06513",
   "metadata": {},
   "source": [
    "# Cell 17 â€” Model Comparison & Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c67ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Argmax_ACC</th>\n",
       "      <th>Argmax_F1W</th>\n",
       "      <th>Best_t(VAL)</th>\n",
       "      <th>Test_ACC@t</th>\n",
       "      <th>Test_F1W@t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ResNet101V2</td>\n",
       "      <td>0.70229</td>\n",
       "      <td>0.696346</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.671756</td>\n",
       "      <td>0.682073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Argmax_ACC  Argmax_F1W  Best_t(VAL)  Test_ACC@t  Test_F1W@t\n",
       "0  ResNet101V2     0.70229    0.696346         0.37    0.671756    0.682073"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† BEST MODEL = ResNet101V2 | Test_ACC@t=0.6718 | Test_F1W@t=0.6821 | Best_t=0.37\n",
      "âœ… Saved: erythema_augtrain_cleanval_best3_results.csv\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).sort_values(\"Test_F1W@t\", ascending=False).reset_index(drop=True)\n",
    "display(results_df)\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "print(f\"\\nðŸ† BEST MODEL = {best['Model']} | Test_ACC@t={best['Test_ACC@t']:.4f} | Test_F1W@t={best['Test_F1W@t']:.4f} | Best_t={best['Best_t(VAL)']:.2f}\")\n",
    "\n",
    "results_df.to_csv(\"erythema_augtrain_cleanval_best3_results.csv\", index=False)\n",
    "print(\"âœ… Saved: erythema_augtrain_cleanval_best3_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9bfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATASET SUMMARY (ERYTHEMA) =====\n",
      "Train (aug): 2778\n",
      "Val   (clean): 66\n",
      "Test  (clean): 131\n",
      "Total: 2975\n",
      "\n",
      "===== SPLIT RATIO =====\n",
      "Train: 93.38%\n",
      "Val:   2.22%\n",
      "Test:  4.40%\n",
      "\n",
      "===== CLASS DISTRIBUTION =====\n",
      "Train:\n",
      " answer\n",
      "Non-existent    2004\n",
      "Existent         774\n",
      "Name: count, dtype: int64\n",
      "Val:\n",
      " answer\n",
      "Non-existent    44\n",
      "Existent        22\n",
      "Name: count, dtype: int64\n",
      "Test:\n",
      " answer\n",
      "Non-existent    91\n",
      "Existent        40\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class indices: {'Existent': 0, 'Non-existent': 1}\n",
      "\n",
      "===== CONFUSION MATRIX =====\n",
      "[[18 22]\n",
      " [17 74]]\n",
      "\n",
      "===== RECALL =====\n",
      "Recall (Existent) = 0.4500\n",
      "\n",
      "===== CLASSIFICATION REPORT =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Existent     0.5143    0.4500    0.4800        40\n",
      "Non-existent     0.7708    0.8132    0.7914        91\n",
      "\n",
      "    accuracy                         0.7023       131\n",
      "   macro avg     0.6426    0.6316    0.6357       131\n",
      "weighted avg     0.6925    0.7023    0.6963       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------- Dataset counts + ratios ----------\n",
    "n_train = len(train_df)\n",
    "n_val   = len(val_df)\n",
    "n_test  = len(test_df)\n",
    "n_total = n_train + n_val + n_test\n",
    "\n",
    "print(\"===== DATASET SUMMARY (ERYTHEMA) =====\")\n",
    "print(f\"Train (aug): {n_train}\")\n",
    "print(f\"Val   (clean): {n_val}\")\n",
    "print(f\"Test  (clean): {n_test}\")\n",
    "print(f\"Total: {n_total}\")\n",
    "\n",
    "print(\"\\n===== SPLIT RATIO =====\")\n",
    "print(f\"Train: {n_train/n_total:.2%}\")\n",
    "print(f\"Val:   {n_val/n_total:.2%}\")\n",
    "print(f\"Test:  {n_test/n_total:.2%}\")\n",
    "\n",
    "print(\"\\n===== CLASS DISTRIBUTION =====\")\n",
    "print(\"Train:\\n\", train_df[\"answer\"].value_counts())\n",
    "print(\"Val:\\n\",   val_df[\"answer\"].value_counts())\n",
    "print(\"Test:\\n\",  test_df[\"answer\"].value_counts())\n",
    "\n",
    "\n",
    "# ---------- Recall computation ----------\n",
    "# after you already have: y_true, y_pred from eval_on_test or eval_threshold\n",
    "\n",
    "labels_map = {v: k for k, v in train_gen.class_indices.items()}\n",
    "print(\"\\nClass indices:\", train_gen.class_indices)\n",
    "\n",
    "# find which index is \"Existent\"\n",
    "if \"Existent\" in train_gen.class_indices:\n",
    "    ex_idx = train_gen.class_indices[\"Existent\"]\n",
    "else:\n",
    "    ex_idx = 1  # fallback\n",
    "\n",
    "# Confusion matrix (order: [0,1] by default)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"\\n===== CONFUSION MATRIX =====\")\n",
    "print(cm)\n",
    "\n",
    "# Recall for Existent = TP / (TP + FN)\n",
    "# TP is cm[ex_idx, ex_idx]\n",
    "# FN is sum of row ex_idx except TP -> cm[ex_idx, 1-ex_idx] (binary)\n",
    "tp = cm[ex_idx, ex_idx]\n",
    "fn = cm[ex_idx, :].sum() - tp\n",
    "recall_existent = tp / (tp + fn + 1e-9)\n",
    "\n",
    "print(\"\\n===== RECALL =====\")\n",
    "print(f\"Recall (Existent) = {recall_existent:.4f}\")\n",
    "\n",
    "# Full report includes recall for each class\n",
    "print(\"\\n===== CLASSIFICATION REPORT =====\")\n",
    "target_names = [labels_map[i] for i in range(len(labels_map))]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
